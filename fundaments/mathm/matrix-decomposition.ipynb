{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c72b120",
   "metadata": {},
   "source": [
    "# Matrix Decompositions\n",
    "## 4.1 Matrix and Trace\n",
    "### Theorem 4.1. For any square matrix $A\\in\\mathbb{R}^{n \\times n}$ A is invirtible if $\\det{A}\\ne0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "3123d2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is invertible\n",
      "True\n",
      "Is invertible\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "def matrix(size=(2,2),square=True):\n",
    "    torch.manual_seed(17)\n",
    "    if square:\n",
    "        return torch.rand(size=size)\n",
    "    else:\n",
    "        return torch.rand(size=size)\n",
    "\n",
    "def is_invertible(A):\n",
    "    try:\n",
    "        if A.shape[0] != A.shape[1]:\n",
    "            print(\"Matrix must be square to be invertible!\")\n",
    "            return False\n",
    "        det = torch.linalg.det(A)\n",
    "        if det != 0:\n",
    "            print(\"Is invertible\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"Matrix is singular (determinant is zero)\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking invertibility: {e}\")\n",
    "        return False\n",
    "\n",
    "print(is_invertible(matrix(square=True)))\n",
    "print(is_invertible(matrix(square=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0322c07",
   "metadata": {},
   "source": [
    "The determinant is the product of the diagonal elements, a square matrix $T$ has a upper-triangular matrix if $T_{ij}=0$ for $i>j$ (i.e., the matrix is zero below its diagonal). The lower-trangular matrix is a matrix with zeros above its diagonal, for a triangular matrix $T\\in \\mathbb{R}^{n\\times n}$ the determinant is the product of the diagonal elements: $$\\det(T)=\\prod_iT_{ii}$$\n",
    "This also can be found with its eigenvalues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "27a4a905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "Tu = torch.tensor([[1.0, 2.0, 3.0], # Upper Triangular\n",
    "                  [0.0, 4.0, 5.0],\n",
    "                  [0.0, 0.0, 6.0]])\n",
    "A = matrix(square=True)\n",
    "def all_close(a, b):\n",
    "    return torch.allclose(a, b)\n",
    "def _det_eig(A):\n",
    "    return torch.prod(torch.linalg.eigvals(A)).real\n",
    "# Triangular Matrix\n",
    "print(all_close(torch.prod(torch.diag(Tu)), torch.linalg.det(Tu)))  \n",
    "# Eigenvalues (this holds for all square matrices)\n",
    "print(all_close(torch.prod(_det_eig(A)), torch.linalg.det(A)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e494ac3d",
   "metadata": {},
   "source": [
    "### Theorem 4.2. (Laplace Expansion). $A\\in \\mathbb{R}^{n\\times n}$. $\\forall j \\in {1,...,n}$:\n",
    "1. Expansion along column $j$\n",
    "$$\\det{A}=\\sum_k(-1)^{k+j}a_{kj}\\det(A_{k,j})$$\n",
    "2. Expansion along row $j$\n",
    "$$\\det{A}=\\sum_k(-1)^{j+k}a_{jk}\\det(A_{j,k})$$\n",
    "Here $A_{k,j}\\in\\mathbb{R}^{(n-1)\\times (n-1)}$ is the submatrix of $A$ that we obtain when deleting row $k$ and column $j$. This what torch does naturally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "db626835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "B is a Singular Matrix\n"
     ]
    }
   ],
   "source": [
    "def _det_simple(A):\n",
    "    if A.shape != (2,2):\n",
    "        raise ValueError('Input must be a 2x2 matrix')\n",
    "    return A[0, 0] * A[1, 1] - A[0, 1] * A[1, 0]\n",
    "\n",
    "def _det_expansion(A):\n",
    "    '''Expansion to square matrices with n>2'''\n",
    "    n = A.shape[0]\n",
    "    if n == 1:\n",
    "        return A[0,0]\n",
    "    elif n == 2: \n",
    "        return _det_simple(A)\n",
    "    det = 0 \n",
    "    for j in range(n):\n",
    "        minor = torch.cat([\n",
    "            A[1:, :j],\n",
    "            A[1:, j+1:]\n",
    "        ], dim=1)\n",
    "        det += (-1)**j * A[0, j] * _det_expansion(minor)\n",
    "    return det\n",
    "print(all_close(_det_expansion(A), torch.linalg.det(A))) \n",
    "B = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float32) # Singular Matrix\n",
    "if _det_expansion(B) == 0:\n",
    "    print(f\"B is a Singular Matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd28645",
   "metadata": {},
   "source": [
    "- $\\det(AB)=\\det(A)\\det(B)$\n",
    "- $\\det(A)=\\det(A)^T$\n",
    "- If A is regular $\\det(A^{-1})=\\frac{1}{\\det(A)}$\n",
    "- Determinant is invariant to the choice of basis of a linear mapping\n",
    "- Adding multiple of a column/row to another one does not change $\\det(A)$ \n",
    "- Multiplication of a column/row with $\\lambda\\in\\mathbb{R}$ scales $\\det(A)$ by $\\lambda$. In particular, $\\det(\\lambda A)=\\lambda^n\\det(A)$\n",
    "- Swapping two rows/columns changes the sign of $\\det(A)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98763739",
   "metadata": {},
   "source": [
    "### Definition 4.4. The trace of a matrix $A\\in\\mathbb{R}^{n\\times n}$ \n",
    "Is defined as $$\\text{tr}(A):=\\sum_i^na_{ii}$$\n",
    "The trace is invariant under cyclic permutations $$\\text{tr}(AKL)=\\text{tr}(KLA)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "8c487e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def _trace(A):\n",
    "    a = torch.diag(A)\n",
    "    return torch.sum(a)\n",
    "print(_trace(A) == torch.trace(A)) # Definition of Trace operation\n",
    "a = 3; k = 2; l = 4\n",
    "A = matrix(size=(a, k))\n",
    "K = matrix(size=(k, l))\n",
    "L = matrix(size=(l, a))\n",
    "def cyclic_perm(A, K, L):\n",
    "    return torch.trace(A @ K @ L)\n",
    "print(all_close(cyclic_perm(A,K,L), cyclic_perm(K,L,A)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3ded55",
   "metadata": {},
   "source": [
    "### Definition 4.5 (Characteristic Polynomial). For $\\lambda\\in \\mathbb{R}$ and a square matrix\n",
    "We have \n",
    "$$\n",
    "\\begin{align}\n",
    "p_A(\\lambda) &:= \\det(A - \\lambda I) \\\\\n",
    "             &= c_0 + c_1\\lambda + c_2\\lambda^2 + \\cdots + c_{n-1}\\lambda^{n-1} + (-1)^n\\lambda^n\n",
    "\\end{align}\n",
    "$$\n",
    "This is the characteristic polynomial of $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "85ec7cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.4933)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = matrix(square=True)\n",
    "lmd = torch.tensor([[2]])\n",
    "def char_poly(A, lmd):\n",
    "    n, m = A.shape[0], A.shape[1]\n",
    "    I = torch.eye(n, m)\n",
    "    return torch.det(A - lmd*I)\n",
    "char_poly(A, lmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad51c550",
   "metadata": {},
   "source": [
    "This allow us to compute eigenvalues and eigenvectors "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3974c0d",
   "metadata": {},
   "source": [
    "## Eigenvalues and Eigenvectors\n",
    "Every linear mapping has a unique transformation matrix given an ordered basis.\n",
    "We can interpret linear mapping and their associated transformation by performing an \"eigen\" analysis.\n",
    "### Definition 4.6. $A\\in\\mathbb{R}^{n\\times n}$. Then $\\lambda\\in\\mathbb{R}$ is an eigenvalue of A and $x\\in\\mathbb{R}^n\\{0\\}$\n",
    "The eigenvector then is $Ax=\\lambda x$, often the eigenvectors are sorted in descending order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872aeb4b",
   "metadata": {},
   "source": [
    "### Definition 4.14 $A\\in\\mathbb{R}^{m\\times n}$, we can always obtain a symmetric, positive semidefinite matrix $S\\in\\mathbb{R}^{n\\times n}$\n",
    "We define $$S:=A^TA$$\n",
    "If $rk(A)=n$, then $S:=A^TA$ is symmetric, positive definite.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "e3691019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def _symmetry(A):\n",
    "    return A.T @ A # Dot Product\n",
    "A = matrix(size=(2,2))\n",
    "S = _symmetry(A)\n",
    "print(all_close(S, S.T))\n",
    "print(all_close(S, A.T @ (A.T).T))\n",
    "print(all_close(S, S.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8bd90f",
   "metadata": {},
   "source": [
    "### Theorem 4.15 (Spectral Theorem). $A\\in\\mathbb{R}^{n\\times n}$ is symmetric.\n",
    "There exists an orthonormal basis of the corresponding vector space V consisting of eigenvectors of A, and each eigenvalue is real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "53220d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def _spectral(A):\n",
    "    assert A.shape[0] == A.shape[1], \"A must be Square\" # square\n",
    "    D, P = torch.linalg.eigh(A) # D:eigenvalues, P:eigenvectors\n",
    "    if not all_close(A, A.T):\n",
    "        return False\n",
    "    return all_close(P @ torch.diag(D) @ P.T, A)\n",
    "#  torch.cat((A, A),dim=1) for non-square\n",
    "print(_spectral(S))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dd2952",
   "metadata": {},
   "source": [
    "### Theorem 4.17. The trace of a matrix $A\\in\\mathbb{R}^{n\\times n}$ is the sum of the eigenvalues\n",
    "$$tr(A)=\\sum_i\\lambda_i$$\n",
    "Where $\\lambda_i\\in \\mathbb{C}$ are (possibly repeated) eigenvalues of $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "64893bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _trace(A):\n",
    "    eigs = torch.linalg.eigvalsh(A)\n",
    "    return torch.sum(eigs)\n",
    "all_close(_trace(A), torch.trace(A)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fc133f",
   "metadata": {},
   "source": [
    "## Cholesky Decomposition\n",
    "### Theorem 4.18 (Cholesky Decomposition). For any symmetric $A\\in R^{n\\times n},\\forall x\\in \\mathbb{R}\\ne0$ and $x^TAx>0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "b54cfa6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5918,  0.0000,  0.0000],\n",
      "        [ 0.7519,  0.1425,  0.0000],\n",
      "        [ 1.0269, -0.3922,  0.0464]])\n",
      "True\n",
      "430 μs ± 14.5 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "30.2 μs ± 3 μs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "def _triang(A):\n",
    "    '''Lower triangular matrix'''\n",
    "    Ll = torch.einsum('ij,ij->ij', A, torch.tril(torch.ones_like(A)))\n",
    "    return Ll\n",
    "def _cholesky(A):\n",
    "    n = A.size(0)\n",
    "    L = torch.zeros_like(A)\n",
    "    for j in range(n):\n",
    "        for k in range(j+1):\n",
    "            s = torch.sum(L[j, :k]*L[k, :k])\n",
    "            if j == k:\n",
    "                # Diagonal element\n",
    "                L[j,j] = torch.sqrt(A[j,j]-s)\n",
    "            else:\n",
    "                # Off-diagonal element\n",
    "                L[j,k] = (A[j,k] - s) / L[k,k]\n",
    "    return L\n",
    "A = matrix(size=(3,3))\n",
    "S = _symmetry(A) # Symmetric Positive Definite Matrix\n",
    "print(_cholesky(S))\n",
    "print(all_close(_cholesky(S), torch.cholesky(S)))\n",
    "%timeit _cholesky(S)\n",
    "%timeit torch.cholesky(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b32c5f6",
   "metadata": {},
   "source": [
    "## 4.4 Eigendecomposition and Diagonalization\n",
    "The eigenvalue decomposition requires square matrices. It would be\n",
    "useful to perform a decomposition on general matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a52a5b6",
   "metadata": {},
   "source": [
    "## 4.5 Singular Value Decomposition\n",
    "Fundamental theorem of linear algebrea, because it can be applied to all matrices, not only to square matrices.\n",
    "### Theorem 4.22. (SVD Theorem). $A\\in\\mathbb{R}^{m\\times n}$ with $r\\in[0,\\min(m,n)]$.\n",
    "The SVD of A is a decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "5bde44fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5])\n"
     ]
    }
   ],
   "source": [
    "A = matrix(size=(3, 5))\n",
    "print(A.size())\n",
    "U, S, V = torch.svd(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b6aa42",
   "metadata": {},
   "source": [
    "## 4.6 Matrix Approximation\n",
    "### Definition 4.23 (Spectral Norm of a Matrix). For $x\\in\\mathbb{R}^n\\{0\\}$\n",
    "The spectral norm is $$||A||_2:=\\max_x\\frac{||Ax||_2}{||x||_2}$$\n",
    "Which can also be written as $$||A||_2=\\sigma_{max}(A)$$\n",
    "the largest singular value of the SVD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "d792bed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4816)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _spectral_norm(A):\n",
    "    _, S, _ = torch.svd(A)\n",
    "    return S[0]\n",
    "A = matrix(size=(3, 5))\n",
    "_spectral_norm(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8d99ac",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "1. Compute the determinant using the Laplace expansion (using the first row) and the Sarrus rule "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a2f9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.17 μs ± 170 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n",
      "56 μs ± 1.45 μs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "def _det_expansion(A):\n",
    "    '''Expansion to square matrices with n>2'''\n",
    "    n = A.shape[0]\n",
    "    if n == 1:\n",
    "        return A[0,0]\n",
    "    elif n == 2: \n",
    "        return _det_simple(A)\n",
    "    det = 0 \n",
    "    for j in range(n):\n",
    "        minor = torch.cat([\n",
    "            A[1:, :j],\n",
    "            A[1:, j+1:]\n",
    "        ], dim=1)\n",
    "        det += (-1)**j * A[0, j] * _det_expansion(minor)\n",
    "    return det\n",
    "\n",
    "A = torch.tensor([[[1.,3.,5.],[2.,4.,6.],[0.,2.,4.]]])\n",
    "%timeit _det_expansion(A)\n",
    "%timeit torch.linalg.det(A)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
