{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic of Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks rose to fame in the late 1980s, thanks in part to advancements like the backpropagation algorithm, which allowed for more effective training of multi-layer networks. However, due to challenges such as inefficient training methods and limited computational power, their practical applications were restricted, leading to a decline in widespread interest.\n",
    "\n",
    " Despite this, neural networks did not vanish entirely as a field of study and experienced a resurgence after 2010 under the name *deep learning*. This revival was driven by new architectures, larger datasets, and increased computational capabilities, enabling breakthroughs in areas like image and video classification, speech recognition, and text modeling. Many attribute these successes to the availability of vast training datasets made possible by the digitalization of data in science and industry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Layers\n",
    "Layers are fundamental components that enable infor,ation processing. Each of them is defined:\n",
    "\n",
    "### **1. Input Layer**\n",
    "The input layeer is the first layer of a neural network and is responsible for receiving the initial data to be processed.\n",
    "- **Function**: Provides the input values of the model, like features or variables of a problem.\n",
    "- **Neuron Numbers**: The number of neurons in this layer corresponds to the number of features (or attributes) of the dataset.\n",
    "\n",
    "### **2. Hidden Layers**\n",
    "The hidden layers are the intermediate between the input and the output layer. This layers is where the complex calculations occurs to learn the patterns in the data.\n",
    "- **Function**: Transform inputs in more useful representations for the output layer to produce more precise predictions\n",
    "- **Quantity of layers and neurons**: Could be one or many hidden layers, and the numbers of neurons in each layer depends of the complexity of the problem. A common *architecture* can include two hidden layers with 12 neurons each one.\n",
    "- **Learning**: Hidden layers  uses algorithms like **backpropagation** to adjust the weights and minimize the error within the training.\n",
    "\n",
    "### **3. Output Layers** \n",
    "The **output layer** is the last layer of neural networjs and is responsible of generate the final predictions.\n",
    "- **Function**: Generates the final result based in the transformations realized by the hidden layers.\n",
    "- **Number of neurons**: The number of neurons in this layer depends of the problem:\n",
    "    - For **binary classification**, there are usally one neuron that produces the probability (i.e., sigmoid function)\n",
    "    - For **multi-class classification**, the number of neurons corresponds to the number of classes (softmax funcion)\n",
    "    - For **regression**, there are usually only one neuron that predicts the numeric value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "# only one 3rd party library\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(object):\n",
    "    def __init__(self, sizes):\n",
    "        \"\"\"\n",
    "        Sizes contains the number of neurons in the respective\n",
    "        layers of networks. For example, if the list was [2,3,1]\n",
    "        would be a three layer network with 2, 3, 1 neurons respectively\n",
    "        Biases and weights are initializated randomly, using Gaussian \n",
    "        distribution with mean 0 and variance 1. \n",
    "\n",
    "        NOTE the first layer is assumed to be an input layer and by convention\n",
    "        we won't set any biases for those neurons, since biases are only ever \n",
    "        used in computing the outputs from later layers.\n",
    "        \"\"\"\n",
    "        self.num_layers = (len(sizes))\n",
    "        self.sizes = sizes\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes [1:]]\n",
    "        self.weights = [np.random.randn(y, x)\n",
    "                        for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "                        # tuples with number ofneurons in actual layer,\n",
    "                        # neurons in next layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Layer Neural Networks\n",
    "A neural network takes an input of $p$ variables $ X = (X_1,\\ X_2,\\dots\\ X_p)$ and builds a nonlinear function $f(X)$ to predict the response $Y$. \n",
    "\n",
    "Before I've seen methods like trees, boosting and geralized addtive methods. What distinguishes neural networks from these methods is the particular *structure* of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a Neural Network\n",
    "For a Single Layer Neural Network, the parameters are $ \\beta = (\\beta_0, \\beta_1,\\dots, \\beta_k)$ as well as each of $w_k = w_{k0}, w_{k1}, \\dots, w_{k0})$, $k=1,\\dots, K$. Given observations $(x_i, y_i),\\; i=1,\\dots,n$ we, could fit the model by solving a nonlinear least squares problem\n",
    "\n",
    "$$\n",
    "minimize: \\frac{1}{2}\\sum_{i=1}^{n}(y_i-f(x_i)^2), \\tag{0}\n",
    "$$\n",
    "where\n",
    "$$\n",
    "f(x_i) = \\beta_0 + \\sum_{k=1}^{K}\\beta_{k}g \\left (w_{k0}+ \\sum_{j=1}^{p}w_{kj}x_{ij}\\right) \\tag{1}\n",
    "$$\n",
    "The objective looks simple, but because of the nested arrangement of the parameters and the symmetry of the hidden units, it is not straightforwar to minimize. The problem is nonconvex in the parameters, and hence there are *multiple solutions*.\n",
    "\n",
    "To overcome some of these issues and to protect from overfitting, two general strtegies are employed when fitting a neurla networks:\n",
    "- *Slow Learning*: The model is fit in a somewhat slow iterative fashion, using *gradient descent*. The fitting process is then stopped when overfitting is detected.\n",
    "- *Regularization*: Penalties are imposed on the parameters, usually lasso or ridge.\n",
    "\n",
    "#### Suppose\n",
    "We represent all the parameters in one long vector $\\theta$. Then we can rewrite the objective in (0) as:\n",
    "$$\n",
    "R(\\theta) = \\frac{1}{2}\\sum_{i=1}^{n}(y_i-f_{\\theta}(x_i))^2, \\tag{2}\n",
    "$$ \n",
    "where we make explicit the dependence of $f$ on the parameters. The idea of gradient descent is very simple.\n",
    "\n",
    "1. Start wit a guess $\\theta^0$ for all the parameters in $\\theta$, and set t=0\n",
    "\n",
    "2. Iterate until the objective fails to decrase: \\\n",
    "    (a) Find a vector $\\delta$ that reflects a small change in $\\theta$, such that $\\theta^{t+1}=\\theta^{t}+\\delta$\n",
    "    (b) Set $t\\leftarrow t+1$\n",
    "\n",
    "One can visualize (Figure 10.17) standing in a mountainous terrain, and\n",
    "the goal is to get to the bottom through a series of steps. As long as each\n",
    "step goes downhill, we must eventually get to the bottom. In this case we\n",
    "were lucky, because with our starting guess θ0 we end up at the global\n",
    "minimum. In general we can hope to end up at a (good) local minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backpropagation\n",
    "How do we find the directions to move $\\theta$ so as to decrase the objective $R(\\theta)$ in 2? The gradient of $R(\\theta)$, evaluates at some current value $\\theta=\\theta^m$, is the vector of partial derivatives at that point:\n",
    "$$\n",
    "\\nabla R(\\theta^m)= \\frac{\\partial R(\\theta)}{\\partial\\theta}\\bigg|_{\\theta=\\theta^m} \\tag{3}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The subscript $\\theta=\\theta^m$ means that after computing the vector of derivatives we evaluate it at current guess $\\theta^m$. This gives the direction in $\\theta$-space in which $R(θ)$ increases most rapidly. The idea of gradient descent is to move $θ$ a little in the opposite direction (since we wish to go downhill):\n",
    "$$\n",
    "\\theta^{m+1}\\leftarrow \\theta^m-\\rho\\nabla R(\\theta^m) \\tag{4}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At small learning rate $\\phi$, this step will decrease the objective $R(\\theta)$; i.e.  $R(\\theta^{m+1}) \\leq R(\\theta^m),$ if the gradient vector is zero, then we may have arrived at a minimum of the objective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually in many networks, the calculation is simple because of the *chain rule* of differentation.\n",
    "$$\n",
    "\\frac{dz}{dx}= \\frac{dz}{dy} \\frac{dy}{dx} \n",
    "$$\n",
    "\n",
    "Since $R(\\theta) = \\sum_{i=1}^{n} R_i(\\theta) = \\frac{1}{2}\\sum_{i=1}^{n}(y_i-f_{\\theta}(x_i)^{2})$ is a sum, its gradient is also a sum over the *n* observations, so we will just examine one of these terms,\n",
    "$$\n",
    "R_i({\\theta}) = \\frac{1}{2}\\left(y_i - \\beta_0-\\sum_{k=1}^{K}\\beta_k g(w_{k0} + \\sum_{j=1}^{p}w_{kj}x_{ij})\\right)^2 \\tag{5}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify the expressions to follow, we write $z_{ik} = w_{k0} + \\sum_{j=1}^{p}w_{kj}x_{ij}$ \\\n",
    "First we take the derivative with respect to $\\beta_k$:\n",
    "$$\n",
    "\\frac{\\partial R_i(\\theta)}{\\partial \\beta_k} = \\frac{\\partial R_i(\\theta)}{\\partial f_{\\theta}(x_i)} \\cdot \\frac{\\partial f_{\\theta}(x_i) }{\\partial \\beta_k}  \\\\[5mm]\n",
    "\\boxed{= -(y_i - f_{\\theta}(x_i)) \\cdot g(z_{ik})} \\tag{6}\n",
    "$$\n",
    "And now we take the derivative with respect to $w_{kj}$:\n",
    "$$\n",
    "\\frac{\\partial R_i(\\theta)}{\\partial w_{kj}} = \\frac{\\partial R_i(\\theta)}{\\partial f_{\\theta}(x_i)} \\cdot \\frac{\\partial f_{\\theta}(x_i)}{\\partial g(z_{ik})} \\cdot \\frac{\\partial g(z_{ik})}{\\partial z_{ik}} \\cdot \\frac{\\partial z_{ik}}{w_{kj}}  \\\\[5mm] \n",
    "\\boxed{= -(y_i- f_{\\theta}(x_i)) \\cdot \\beta_k \\cdot g'(z_{ik}) \\cdot x_{ij}} \\tag{7}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that both these expressions contain the residual $y_i - f_{theta}(x_i)$. In (6) we see that a fraction of that residual gets attributed to each of the hidden units according to the value of $g_{ik}$. Then in (7) we see a similar attribution to input $j$ via hidden unit $k$.\n",
    "So the act of diferentiation assigns a fraction of the residual to each of the parameters via the chain rule —  a process known as *backpropagation* in the neural network literature. Although these calculations are straightforward, it takes careful bookkeeping to keep track of all the pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(object):    \n",
    "    def backprop(self, x, y):\n",
    "        \"\"\"\n",
    "        Return a tuple ``(nabla_b, nabla_w)`` representing the gradient \n",
    "        for the cost function C_x ``nabla_b`` and ``nabla_w`` are layer by layer\n",
    "        lists of numpy arrays, similar to ``self.biases`` and ``self.weights``\n",
    "\n",
    "        \"\"\"\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        # feedforward\n",
    "        activation = x\n",
    "        activations = [x] #list to store all the activations, layer by layer\n",
    "        zs = [] #list to store all the z vectors, layer by layer\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            z = np.dot(w, activation) + b\n",
    "            zs.append(z)\n",
    "            activation = sigmoid(z)\n",
    "            activations.append(activation)\n",
    "        # backward pass\n",
    "        delta = self.cost_derivative(activations[-1], y) * \\\n",
    "            sigmoid_prime(zs[-1])\n",
    "        nabla_b[-1] = delta\n",
    "        nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n",
    "\n",
    "        for l in range(2, self.num_layers):\n",
    "            z = zs[-l]\n",
    "            sp = sigmoid_prime(z)\n",
    "            delta = np.dot(self.weights[-l+1].transpose(), delta) * sp\n",
    "            nabla_b[-l] = delta\n",
    "            nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())\n",
    "        return (nabla_b, nabla_w)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Regularization and Stochastic Gradient Descent**\n",
    "Gradient descent takes takes many steps to reach a local minimum. There are a number of approaches for accelerating the process. Also, when *n* is large, instead of summing (6)-(7) over all *n* observations, we can sample a small fraction widely known as **mini-batch** of them each time we compute a gradient step. \n",
    "\n",
    "This process is known as **stochastic gradient descent** (SGD) and is `the state of the art for learning deep neural networks. Fortunately, there is very good software for setting up deep learning models, and for fitting them to data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularization is essential here to avoid overfitting. Taking for example *ridge regularization* for the  MNSIT dataset which takes 9 inputs (numbers) $(x_i)$. \n",
    "$$ \n",
    "R(\\theta; \\lambda) = -\\sum_{i=1}^{n} \\sum_{m=0}^{9}y_{im}log(f_m(x_i)) + \\lambda \\sum_{j}\\theta_j^2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter $\\lambda$ is often preset at a small value or else it is found using validation-set approach. We can also use different values of $\\lambda$ for the groups of weights from different layers; in this case *$W_1$* and *$W_2$* were penalized. We need two things:\n",
    "\n",
    "a. term that penalizes large weights and is controlled by the hyperparameter $\\lambda$.\n",
    "$$\n",
    "C = C_0+\\frac{\\lambda}{2n}\\sum_{w}w^2\n",
    "$$\n",
    "b. a weight update rule\n",
    "$$\n",
    "w \\leftarrow w-\\eta \\left(\\frac{\\partial C_0}{\\partial w} + \\frac{\\lambda}{n}w \\right)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which could be implemented as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "weights = [(1 - eta * (lmbda / n)) * w - (eta / len(mini_batch)) * nw\n",
    "                for w, nw in zip(weights, nabla_w)]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(object):    \n",
    "    def SGD(self, training_data, epochs, mini_batch_size, eta, test_data=None):\n",
    "        \"\"\"\n",
    "        Train the neural network using mini-batch stochastic gradient descent.\n",
    "        ``training_data`` is a list of tuples ``(x, y)`` representing the training\n",
    "        inputs and the desired outputs. The non-optional parameters are self \n",
    "        explanatory. If ``test_data`` is provided then the network will be evaluated\n",
    "        against the test data after each epoch, and partial progress printed out.\n",
    "        \"\"\"\n",
    "        if test_data:\n",
    "            n_test = len(test_data)  \n",
    "        n = len(training_data)  # stores the total number of training examples\n",
    "        for j in range(epochs): # training loop\n",
    "            time1 = time.time()\n",
    "            random.shuffle(training_data)\n",
    "            mini_batches = [    # mini batch creation\n",
    "                training_data[k:k+mini_batch_size]\n",
    "                for k in range(0, n, mini_batch_size)]\n",
    "            for mini_batch in mini_batches:\n",
    "                self.update_mini_batch(mini_batch, eta, lmbda, n)\n",
    "            time2 = time.time()\n",
    "            if test_data:\n",
    "                print(\"Epoch {0}: {1} / {2}, took {3:.2f} seconds\".format(\n",
    "                    j, self.evaluate(test_data), n_test, time2-time1))\n",
    "            else:\n",
    "                print(\"Epoch {0} complete in {1:.2f} seconds\".format(j, time2-time1))\n",
    "\n",
    "    def update_mini_batch(self, mini_batch, eta, lmbda, n):\n",
    "        \"\"\"\n",
    "        Update the network's weights and biases by applying grad des using\n",
    "        backpropagation to a single mini batch,\n",
    "        Mini-batch is just a list of tuples ``(x, y)`` and ``eta`` the \n",
    "        learning rate\n",
    "        \"\"\"\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]  # 1. initialize\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights] #    gradients accumulators\n",
    "        for x,y in mini_batch:  # 2. process each example (iterate over mini-batch)\n",
    "            delta_nabla_b, delta_nabla_w = self.backprop(x, y) # 3. update weights and biases\n",
    "            nabla_b = [nb + dnb for nb, dnb in zip(nabla_b, delta_nabla_b)] # accumulate gradients\n",
    "            nabla_w = [nb + dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
    "        # update weights with L2 regularization\n",
    "        self.weights = [(1 - eta * (lmbda / n)) *w -(eta/len(mini_batch)) # 4. update weights and biases\n",
    "                        for w, nw in zip(self.weights, nabla_w)]\n",
    "        # obviously bias doesnt need regularization\n",
    "        self.biases = [b-(eta/len(mini_batch))*nb\n",
    "                    for b, nb in zip(self.biases, nabla_b)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(object):\n",
    "    def __init__(self, sizes):\n",
    "        \"\"\"\n",
    "        Sizes contains the number of neurons in the respective\n",
    "        layers of networks. For example, if the list was [2,3,1]\n",
    "        would be a three layer network with 2, 3, 1 neurons respectively\n",
    "        Biases and weights are initializated randomly, using Gaussian \n",
    "        distribution with mean 0 and variance 1. \n",
    "\n",
    "        NOTE the first layer is assumed to be an input layer and by convention\n",
    "        we won't set any biases for those neurons, since biases are only ever \n",
    "        used in computing the outputs from later layers.\n",
    "        \"\"\"\n",
    "        self.num_layers = (len(sizes))\n",
    "        self.sizes = sizes\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes [1:]]\n",
    "        self.weights = [np.random.randn(y, x)\n",
    "                        for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "                        # tuples with number ofneurons in actual layer,\n",
    "                        # neurons in next layer\n",
    "\n",
    "    def backprop(self, x, y):\n",
    "        \"\"\"\n",
    "        Return a tuple ``(nabla_b, nabla_w)`` representing the gradient \n",
    "        for the cost function C_x ``nabla_b`` and ``nabla_w`` are layer by layer\n",
    "        lists of numpy arrays, similar to ``self.biases`` and ``self.weights``\n",
    "\n",
    "        \"\"\"\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        # feedforward\n",
    "        activation = x\n",
    "        activations = [x] #list to store all the activations, layer by layer\n",
    "        zs = [] #list to store all the z vectors, layer by layer\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            z = np.dot(w, activation) + b\n",
    "            zs.append(z)\n",
    "            activation = sigmoid(z)\n",
    "            activations.append(activation)\n",
    "        # backward pass\n",
    "        delta = self.cost_derivative(activations[-1], y) * \\\n",
    "            sigmoid_prime(zs[-1])\n",
    "        nabla_b[-1] = delta\n",
    "        nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n",
    "\n",
    "        for l in range(2, self.num_layers):\n",
    "            z = zs[-l]\n",
    "            sp = sigmoid_prime(z)\n",
    "            delta = np.dot(self.weights[-l+1].transpose(), delta) * sp\n",
    "            nabla_b[-l] = delta\n",
    "            nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())\n",
    "        return (nabla_b, nabla_w)\n",
    "    \n",
    "    def feedforward(self, a):\n",
    "        \"\"\"\n",
    "        Return the output of the network\n",
    "        \"\"\"\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            a = sigmoid(np.dot(w, a) + b)\n",
    "        return a # activaction of the neurons in the current layer of the NN\n",
    "\n",
    "    def SGD(self, training_data, epochs, mini_batch_size, eta, lmbda, test_data=None):\n",
    "        \"\"\"\n",
    "        Train the neural network using mini-batch stochastic gradient descent.\n",
    "        ``training_data`` is a list of tuples ``(x, y)`` representing the training\n",
    "        inputs and the desired outputs. The non-optional parameters are self \n",
    "        explanatory. If ``test_data`` is provided then the network will be evaluated\n",
    "        against the test data after each epoch, and partial progress printed out.\n",
    "        \"\"\"\n",
    "        if test_data:\n",
    "            n_test = len(test_data)  \n",
    "        n = len(training_data)  # stores the total number of training examples\n",
    "        for j in range(epochs): # training loop\n",
    "            time1 = time.time()\n",
    "            random.shuffle(training_data)\n",
    "            mini_batches = [    # mini batch creation\n",
    "                training_data[k:k+mini_batch_size]\n",
    "                for k in range(0, n, mini_batch_size)]\n",
    "            for mini_batch in mini_batches:\n",
    "                self.update_mini_batch(mini_batch, eta, lmbda, n)\n",
    "            time2 = time.time()\n",
    "            if test_data:\n",
    "                print(\"Epoch {0}: {1} / {2}, took {3:.2f} seconds\".format(\n",
    "                    j, self.evaluate(test_data), n_test, time2-time1))\n",
    "            else:\n",
    "                print(\"Epoch {0} complete in {1:.2f} seconds\".format(j, time2-time1))\n",
    "\n",
    "    def update_mini_batch(self, mini_batch, eta, lmbda, n):\n",
    "        \"\"\"\n",
    "        Update the network's weights and biases by applying grad des using\n",
    "        backpropagation to a single mini batch,\n",
    "        Mini-batch is just a list of tuples ``(x, y)`` and ``eta`` the \n",
    "        learning rate\n",
    "        \"\"\"\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]  # 1. initialize\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights] #    gradients accumulators\n",
    "        for x,y in mini_batch:  # 2. process each example (iterate over mini-batch)\n",
    "            delta_nabla_b, delta_nabla_w = self.backprop(x, y) # 3. update weights and biases\n",
    "            nabla_b = [nb + dnb for nb, dnb in zip(nabla_b, delta_nabla_b)] # accumulate gradients\n",
    "            nabla_w = [nw + dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
    "        # update weights with L2 regularization\n",
    "        self.weights = [(1 - eta * (lmbda / n)) *w -(eta/len(mini_batch)) # 4. update weights and biases\n",
    "                        for w, nw in zip(self.weights, nabla_w)]\n",
    "        # obviously bias doesnt need regularization\n",
    "        self.biases = [b-(eta/len(mini_batch))*nb\n",
    "                    for b, nb in zip(self.biases, nabla_b)]\n",
    "\n",
    "    def evaluate(self, test_data):\n",
    "        \"\"\"\n",
    "        Return the number of test inputs for which the neural netwokr outputs\n",
    "        the correct result. Note that the neural network's output is assumed \n",
    "        to be the index of whichever neuron in the final layer has the highest \n",
    "        activation\n",
    "        \"\"\"\n",
    "        test_results = [(np.argmax(self.feedforward(x)), y)\n",
    "                        for (x, y) in test_data]\n",
    "        return sum(int(x==y) for (x, y) in test_results)\n",
    "    \n",
    "    def cost_derivative(self, output_activations, y): #loss function\n",
    "        r\"\"\"\n",
    "        Return the vector of partial derivatives \\partial C_x/ \n",
    "        \\partial a for the output activations.\n",
    "        \"\"\"\n",
    "        return (output_activations - y) # original cost function (cross entropy or MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Miscellaneous functions\n",
    "def sigmoid(z):\n",
    "    \"\"\"The sigmoid function.\"\"\"\n",
    "    return 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "    \"\"\"Derivative of the sigmoid function.\"\"\"\n",
    "    return sigmoid(z)*(1-sigmoid(z))\n",
    "\n",
    "# One-hot encoding for labels\n",
    "def vectorized_result(j):\n",
    "    e = np.zeros((10, 1))\n",
    "    e[j] = 1.0\n",
    "    return e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implemmenting it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# fetch the MNIST dataset\n",
    "mnist = fetch_openml('mnist_784', as_frame=False)\n",
    "\n",
    "# extract the data and labels\n",
    "X, y = mnist.data.astype(np.float32), mnist.target.astype(np.int32)\n",
    "\n",
    "# normalize the data to the range [0, 1]\n",
    "X /= 255.0\n",
    "\n",
    "X_train, X_test = X[:60000], X[60000:]\n",
    "y_train, y_test = y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load MNIST data\n",
    "def load_data():\n",
    "    from sklearn.datasets import fetch_openml\n",
    "    mnist = fetch_openml('mnist_784', as_frame=False)\n",
    "    X, y = mnist.data.astype(np.float32), mnist.target.astype(np.int32)\n",
    "    X /= 255.0  # Normalize pixel values to [0, 1]\n",
    "    X_train, X_test = X[:60000], X[60000:]\n",
    "    y_train, y_test = y[:60000], y[60000:]\n",
    "    training_inputs = [np.reshape(x, (784, 1)) for x in X_train]\n",
    "    training_results = [vectorized_result(y) for y in y_train]\n",
    "    training_data = list(zip(training_inputs, training_results))\n",
    "    test_inputs = [np.reshape(x, (784, 1)) for x in X_test]\n",
    "    test_data = list(zip(test_inputs, y_test))\n",
    "    return training_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(training_data[1][:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_32172\\1919651058.py:4: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0/(1.0+np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 1135 / 10000, took 12.42 seconds\n",
      "Epoch 1: 1135 / 10000, took 11.82 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[109], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m training_data, test_data \u001b[38;5;241m=\u001b[39m load_data()\n\u001b[0;32m      4\u001b[0m net \u001b[38;5;241m=\u001b[39m Network([\u001b[38;5;241m784\u001b[39m, \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m10\u001b[39m])\n\u001b[1;32m----> 5\u001b[0m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSGD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmini_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlmbda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[102], line 80\u001b[0m, in \u001b[0;36mNetwork.SGD\u001b[1;34m(self, training_data, epochs, mini_batch_size, eta, lmbda, test_data)\u001b[0m\n\u001b[0;32m     76\u001b[0m mini_batches \u001b[38;5;241m=\u001b[39m [    \u001b[38;5;66;03m# mini batch creation\u001b[39;00m\n\u001b[0;32m     77\u001b[0m     training_data[k:k\u001b[38;5;241m+\u001b[39mmini_batch_size]\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, n, mini_batch_size)]\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mini_batch \u001b[38;5;129;01min\u001b[39;00m mini_batches:\n\u001b[1;32m---> 80\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_mini_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmini_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlmbda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m time2 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m test_data:\n",
      "Cell \u001b[1;32mIn[102], line 98\u001b[0m, in \u001b[0;36mNetwork.update_mini_batch\u001b[1;34m(self, mini_batch, eta, lmbda, n)\u001b[0m\n\u001b[0;32m     96\u001b[0m nabla_w \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mzeros(w\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights] \u001b[38;5;66;03m#    gradients accumulators\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x,y \u001b[38;5;129;01min\u001b[39;00m mini_batch:  \u001b[38;5;66;03m# 2. process each example (iterate over mini-batch)\u001b[39;00m\n\u001b[1;32m---> 98\u001b[0m     delta_nabla_b, delta_nabla_w \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackprop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# 3. update weights and biases\u001b[39;00m\n\u001b[0;32m     99\u001b[0m     nabla_b \u001b[38;5;241m=\u001b[39m [nb \u001b[38;5;241m+\u001b[39m dnb \u001b[38;5;28;01mfor\u001b[39;00m nb, dnb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(nabla_b, delta_nabla_b)] \u001b[38;5;66;03m# accumulate gradients\u001b[39;00m\n\u001b[0;32m    100\u001b[0m     nabla_w \u001b[38;5;241m=\u001b[39m [nw \u001b[38;5;241m+\u001b[39m dnw \u001b[38;5;28;01mfor\u001b[39;00m nw, dnw \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(nabla_w, delta_nabla_w)]\n",
      "Cell \u001b[1;32mIn[102], line 51\u001b[0m, in \u001b[0;36mNetwork.backprop\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     49\u001b[0m     delta \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights[\u001b[38;5;241m-\u001b[39ml\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mtranspose(), delta) \u001b[38;5;241m*\u001b[39m sp\n\u001b[0;32m     50\u001b[0m     nabla_b[\u001b[38;5;241m-\u001b[39ml] \u001b[38;5;241m=\u001b[39m delta\n\u001b[1;32m---> 51\u001b[0m     nabla_w[\u001b[38;5;241m-\u001b[39ml] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43ml\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (nabla_b, nabla_w)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Main script\n",
    "if __name__ == \"__main__\":\n",
    "    training_data, test_data = load_data()\n",
    "    net = Network([784, 30, 10])\n",
    "    net.SGD(training_data, epochs=10, mini_batch_size=10, eta=.01, test_data=test_data, lmbda=1e-3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout Learning\n",
    "Is a form of regularization, similar in some respects to ridge regularization. Inspired by random forests, the idea is to randomly remove a fraction $\\phi$, this is done separately each time a training observation is processed. \n",
    "\n",
    "The surviving units stand in for those missing, and their weights are scaled up by a factor of $1/(1 − \\phi)$ to compensate. This prevents nodes from becoming over-specialized, and can be seen as a form of regularization. In practice dropout is achieved by randomly set￾ting the activations for the “dropped out” units to zero, while keeping the\n",
    "architecture intact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolation and Double Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These concepts are important phenomena in the field of machine learning, particularly when dealing with overparamaterized models.\n",
    "#### **Interpolation**\n",
    "Occurs when a model is complex enough to perfectly fit the training data, meaning that it can pass through every single training point without any error.\n",
    "\n",
    "This typically happens when the number of parameters in the model exceeds the number of data points, allowing the model to find solutions that exactly match the training set. In traditional statistical learning theory, reaching this interpolation theshold was ofted associated with overfitting,, where the model performs well on training data but poorly on unseen test data.\n",
    "\n",
    "#### **Double Descent**\n",
    "Double descent refers to a surprising phenomenon observed in the relationship between model complexity (e.g., number of parameters) and generalization error. Traditionally, as you increase the complexity of a model, the error decreases up to a point, after which it increases due to overfitting. However, in the case of double descent, beyond the interpolation threshold—where the model has enough capacity to perfectly fit the training data—the error begins to decrease again, leading to a second descent in the error curve\n",
    "\n",
    "This behavior can be explained by the fact that very large models, despite their capacity to overfit, also have the ability to generalize well if trained appropriately. For instance, overparameterized deep networks might **interpolate noisy data** yet still exhibit good generalization performance. The mechanism behind this involves not only fitting the data but doing so in a way that implicitly prefers simpler solutions among all possible interpolating ones, a property sometimes referred to as \"*smooth interpolation*\".\n",
    "\n",
    "In summary, while increasing model complexity usually leads to an initial rise in test error past a certain point due to overfitting, for sufficiently complex models like those used in modern deep learning, there’s often a second phase where further increasing the model size improves generalization, resulting in what we call the double descent curve."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
